# === bybit-listener.py ===
import json
import pandas as pd
import os
import threading
import schedule
import logging
from logging.handlers import RotatingFileHandler
from datetime import datetime
import yaml
import pytz
import time
from pybit.unified_trading import WebSocket
from websocket import WebSocketConnectionClosedException  # Ensure websocket-client is installed

# Load configuration
with open('config.yaml', 'r') as f:
    config = yaml.safe_load(f)

with open('symbols.json', 'r') as f:
    symbols_config = json.load(f)

# Setup logging with rotation and console output
log_dir = os.path.dirname(config['log_file'])
os.makedirs(log_dir, exist_ok=True)

# Initialize RotatingFileHandler
file_handler = RotatingFileHandler(
    config['log_file'],
    maxBytes=5 * 1024 * 1024,  # 5 MB per log file
    backupCount=5,
    encoding='utf-8'
)

# Initialize ConsoleHandler
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)
console_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
console_handler.setFormatter(console_formatter)

# Set up the logger
logger = logging.getLogger()
logger.setLevel(logging.INFO)
logger.addHandler(file_handler)
logger.addHandler(console_handler)


class BybitListener:
    def __init__(self, symbols, storage_path, timezone, max_storage_gb=3):
        self.symbols = symbols
        self.storage_path = storage_path
        self.timezone = pytz.timezone(timezone)
        self.max_storage_bytes = max_storage_gb * (1024 ** 3)  # Convert GB to bytes
        self.data = {}
        self.lock = threading.Lock()
        self.ws = None
        self.initialize_data_storage()

    def initialize_data_storage(self):
        for symbol in self.symbols:
            self.data[symbol['name']] = {}
            for category in symbol['categories']:
                base_category = category.split('.')[0]
                self.data[symbol['name']][base_category] = []

    def handle_message(self, message):
        """Handle messages received from the WebSocket."""
        try:
            topic = message.get('topic')
            if not topic:
                logger.warning("Malformed message: %s", message)
                return

            topic_parts = topic.split('.')
            category = topic_parts[0]
            symbol_name = topic_parts[1] if len(topic_parts) > 1 else None

            if symbol_name and category:
                with self.lock:
                    if symbol_name in self.data and category in self.data[symbol_name]:
                        self.data[symbol_name][category].append(message)
                        logger.info("Received data for %s - %s", symbol_name, category)
                    else:
                        logger.warning("Received data for untracked symbol or category: %s - %s", symbol_name, category)
        except Exception as e:
            logger.error("Error handling message: %s", e, exc_info=True)

    def start_ws(self):
        """Start the WebSocket connection."""
        while True:
            try:
                # Retrieve channel_type from config
                channel_type = config.get("channel_type", "linear")
                logger.info(f"Initializing WebSocket with channel_type: {channel_type} (Type: {type(channel_type)})")

                # Initialize WebSocket with the correct channel_type
                self.ws = WebSocket(
                    testnet=config.get("testnet", False),
                    channel_type=channel_type
                )

                # Subscribe to streams
                for symbol in self.symbols:
                    symbol_name = symbol.get('name')
                    categories = symbol.get('categories', [])
                    if isinstance(symbol_name, str) and isinstance(categories, list):
                        for category in categories:
                            if isinstance(category, str):
                                full_topic = f"{category}.{symbol_name}"
                                logger.info(f"Preparing to subscribe to topic: {full_topic}")
                                # Subscribe using the full topic
                                self.ws.subscribe(
                                    topic=full_topic,
                                    callback=self.handle_message
                                )
                                logger.info(f"Subscribed to topic: {full_topic}")
                            else:
                                logger.error(f"Invalid category type for symbol {symbol_name}: {type(category)}")
                    else:
                        logger.error(f"Invalid symbol or categories: {symbol}")

                logger.info("Subscribed to all streams.")

                # Keep the thread alive
                while True:
                    time.sleep(1)

            except WebSocketConnectionClosedException as e:
                logger.error("WebSocket connection closed: %s", e, exc_info=True)
                logger.info("Attempting to reconnect in 5 seconds...")
                time.sleep(5)
            except Exception as e:
                logger.error("Unexpected error in WebSocket connection: %s", e, exc_info=True)
                logger.info("Attempting to reconnect in 5 seconds...")
                time.sleep(5)

    def save_data(self):
        """Save collected data to Parquet files."""
        try:
            with self.lock:
                current_date = datetime.now(self.timezone).strftime("%Y-%m-%d")
                for symbol, categories in self.data.items():
                    for category, records in categories.items():
                        if records:
                            df = pd.DataFrame(records)
                            # Define directory for the symbol and category
                            dir_path = os.path.join(self.storage_path, symbol, category)
                            os.makedirs(dir_path, exist_ok=True)
                            file_path = os.path.join(dir_path, f"{current_date}.parquet")
                            df.to_parquet(file_path, engine='pyarrow', compression='snappy')
                            logger.info("Saved %d records to %s", len(records), file_path)
                            # Clear the data after saving
                            self.data[symbol][category] = []
                logger.info("Data saved for date: %s", current_date)

            # After saving, manage storage to ensure it doesn't exceed the limit
            self.manage_storage()
        except Exception as e:
            logger.error("Error during save_data: %s", e, exc_info=True)

    def manage_storage(self):
        """Ensure storage usage stays within the maximum limit."""
        try:
            total_size = 0
            parquet_files = []

            # Traverse through all parquet files in storage_path
            for root, dirs, files in os.walk(self.storage_path):
                for file in files:
                    if file.endswith('.parquet'):
                        file_path = os.path.join(root, file)
                        try:
                            file_size = os.path.getsize(file_path)
                            total_size += file_size
                            parquet_files.append((file_path, os.path.getmtime(file_path)))
                        except OSError as e:
                            logger.error("Error accessing file %s: %s", file_path, e)

            logger.info("Total parquet storage size: %.2f GB", total_size / (1024 ** 3))

            # If total size exceeds the maximum allowed, delete oldest files
            if total_size > self.max_storage_bytes:
                # Sort files by modification time (oldest first)
                parquet_files.sort(key=lambda x: x[1])
                for file_path, mod_time in parquet_files:
                    try:
                        file_size = os.path.getsize(file_path)
                        os.remove(file_path)
                        total_size -= file_size
                        logger.info("Deleted old parquet file: %s to manage storage.", file_path)
                        if total_size <= self.max_storage_bytes:
                            break
                    except OSError as e:
                        logger.error("Error deleting file %s: %s", file_path, e)

                logger.info("Storage management completed. Current size: %.2f GB", total_size / (1024 ** 3))
        except Exception as e:
            logger.error("Error during manage_storage: %s", e, exc_info=True)


def schedule_saving(listener, save_time):
    """Schedule daily data saving at the specified time."""
    def job():
        listener.save_data()

    schedule.every().day.at(save_time).do(job)
    logger.info("Scheduled daily save at %s.", save_time)

    while True:
        schedule.run_pending()
        time.sleep(1)


def main():
    listener = BybitListener(
        symbols=symbols_config['symbols'],
        storage_path=config['parquet_storage_path'],
        timezone=config['timezone'],
        max_storage_gb=3  # Set maximum storage to 3 GB
    )

    # Start WebSocket listener in a separate thread
    ws_thread = threading.Thread(target=listener.start_ws)
    ws_thread.daemon = True
    ws_thread.start()
    logger.info("WebSocket listener started.")

    # Schedule data saving in a separate thread
    scheduler_thread = threading.Thread(target=schedule_saving, args=(listener, config['save_time']))
    scheduler_thread.daemon = True
    scheduler_thread.start()
    logger.info("Scheduler thread started.")

    # Keep the main thread alive
    try:
        while True:
            time.sleep(10)
    except KeyboardInterrupt:
        logger.info("Shutting down BybitListener.")


if __name__ == "__main__":
    main()


# === combine_files.py ===
import os

def combine_files(input_directory='.', output_file='combined_output.txt', file_extensions=None):
    """
    Combines contents of all files with the specified extensions in the input_directory
    into a single output_file. Each file's content is preceded by a comment with its filename.
    
    Parameters:
    - input_directory (str): Path to the directory containing files to combine.
    - output_file (str): Path to the output file.
    - file_extensions (list of str): List of file extensions to include (e.g., ['.py', '.sh']).
    """
    if file_extensions is None:
        file_extensions = ['.py', '.sh', '.yaml', '.txt', '.json']
    
    # Normalize extensions to lowercase
    file_extensions = [ext.lower() for ext in file_extensions]
    
    # Get absolute path of the input directory
    input_directory = os.path.abspath(input_directory)
    
    # Check if input directory exists
    if not os.path.isdir(input_directory):
        print(f"Error: The directory '{input_directory}' does not exist.")
        return
    
    # Open the output file in write mode
    try:
        with open(output_file, 'w', encoding='utf-8') as outfile:
            # Iterate over all files in the input directory
            for filename in sorted(os.listdir(input_directory)):
                if any(filename.lower().endswith(ext) for ext in file_extensions):
                    file_path = os.path.join(input_directory, filename)
                    try:
                        with open(file_path, 'r', encoding='utf-8') as infile:
                            # Write a comment with the filename
                            outfile.write(f"# === {filename} ===\n")
                            # Write the file's content
                            content = infile.read()
                            outfile.write(content + "\n\n")  # Add extra newline for separation
                        print(f"Added: {filename}")
                    except Exception as e:
                        print(f"Failed to read {filename}: {e}")
    except Exception as e:
        print(f"Failed to write to output file '{output_file}': {e}")
        return

    print(f"\nAll specified files have been combined into '{output_file}'.")

if __name__ == "__main__":
    # You can modify the parameters below as needed
    combine_files(
        input_directory='.',                    # Current directory
        output_file='combined_output.txt',      # Output file name
        file_extensions=['.py', '.sh', '.yaml', '.txt', '.json']  # File extensions to include
    )


# === combined_output.txt ===
# === bybit-listener.py ===
import json
import pandas as pd
import os
import threading
import schedule
import logging
from logging.handlers import RotatingFileHandler
from datetime import datetime
import yaml
import pytz
import time
from pybit.unified_trading import WebSocket
from websocket import WebSocketConnectionClosedException  # Ensure websocket-client is installed

# Load configuration
with open('config.yaml', 'r') as f:
    config = yaml.safe_load(f)

with open('symbols.json', 'r') as f:
    symbols_config = json.load(f)

# Setup logging with rotation and console output
log_dir = os.path.dirname(config['log_file'])
os.makedirs(log_dir, exist_ok=True)

# Initialize RotatingFileHandler
file_handler = RotatingFileHandler(
    config['log_file'],
    maxBytes=5 * 1024 * 1024,  # 5 MB per log file
    backupCount=5,
    encoding='utf-8'
)

# Initialize ConsoleHandler
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)
console_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
console_handler.setFormatter(console_formatter)

# Set up the logger
logger = logging.getLogger()
logger.setLevel(logging.INFO)
logger.addHandler(file_handler)
logger.addHandler(console_handler)


class BybitListener:
    def __init__(self, symbols, storage_path, timezone, max_storage_gb=3):
        self.symbols = symbols
        self.storage_path = storage_path
        self.timezone = pytz.timezone(timezone)
        self.max_storage_bytes = max_storage_gb * (1024 ** 3)  # Convert GB to bytes
        self.data = {}
        self.lock = threading.Lock()
        self.ws = None
        self.initialize_data_storage()

    def initialize_data_storage(self):
        for symbol in self.symbols:
            self.data[symbol['name']] = {}
            for category in symbol['categories']:
                base_category = category.split('.')[0]
                self.data[symbol['name']][base_category] = []

    def handle_message(self, message):
        """Handle messages received from the WebSocket."""
        try:
            topic = message.get('topic')
            if not topic:
                logger.warning("Malformed message: %s", message)
                return

            topic_parts = topic.split('.')
            category = topic_parts[0]
            symbol_name = topic_parts[1] if len(topic_parts) > 1 else None

            if symbol_name and category:
                with self.lock:
                    if symbol_name in self.data and category in self.data[symbol_name]:
                        self.data[symbol_name][category].append(message)
                        logger.info("Received data for %s - %s", symbol_name, category)
                    else:
                        logger.warning("Received data for untracked symbol or category: %s - %s", symbol_name, category)
        except Exception as e:
            logger.error("Error handling message: %s", e, exc_info=True)

    def start_ws(self):
        """Start the WebSocket connection."""
        while True:
            try:
                # Retrieve channel_type from config
                channel_type = config.get("channel_type", "linear")
                logger.info(f"Initializing WebSocket with channel_type: {channel_type} (Type: {type(channel_type)})")

                # Initialize WebSocket with the correct channel_type
                self.ws = WebSocket(
                    testnet=config.get("testnet", False),
                    channel_type=channel_type
                )

                # Subscribe to streams
                for symbol in self.symbols:
                    symbol_name = symbol.get('name')
                    categories = symbol.get('categories', [])
                    if isinstance(symbol_name, str) and isinstance(categories, list):
                        for category in categories:
                            if isinstance(category, str):
                                full_topic = f"{category}.{symbol_name}"
                                logger.info(f"Preparing to subscribe to topic: {full_topic}")
                                # Subscribe using the full topic
                                self.ws.subscribe(
                                    topic=full_topic,
                                    callback=self.handle_message
                                )
                                logger.info(f"Subscribed to topic: {full_topic}")
                            else:
                                logger.error(f"Invalid category type for symbol {symbol_name}: {type(category)}")
                    else:
                        logger.error(f"Invalid symbol or categories: {symbol}")

                logger.info("Subscribed to all streams.")

                # Keep the thread alive
                while True:
                    time.sleep(1)

            except WebSocketConnectionClosedException as e:
                logger.error("WebSocket connection closed: %s", e, exc_info=True)
                logger.info("Attempting to reconnect in 5 seconds...")
                time.sleep(5)
            except Exception as e:
                logger.error("Unexpected error in WebSocket connection: %s", e, exc_info=True)
                logger.info("Attempting to reconnect in 5 seconds...")
                time.sleep(5)

    def save_data(self):
        """Save collected data to Parquet files."""
        try:
            with self.lock:
                current_date = datetime.now(self.timezone).strftime("%Y-%m-%d")
                for symbol, categories in self.data.items():
                    for category, records in categories.items():
                        if records:
                            df = pd.DataFrame(records)
                            # Define directory for the symbol and category
                            dir_path = os.path.join(self.storage_path, symbol, category)
                            os.makedirs(dir_path, exist_ok=True)
                            file_path = os.path.join(dir_path, f"{current_date}.parquet")
                            df.to_parquet(file_path, engine='pyarrow', compression='snappy')
                            logger.info("Saved %d records to %s", len(records), file_path)
                            # Clear the data after saving
                            self.data[symbol][category] = []
                logger.info("Data saved for date: %s", current_date)

            # After saving, manage storage to ensure it doesn't exceed the limit
            self.manage_storage()
        except Exception as e:
            logger.error("Error during save_data: %s", e, exc_info=True)

    def manage_storage(self):
        """Ensure storage usage stays within the maximum limit."""
        try:
            total_size = 0
            parquet_files = []

            # Traverse through all parquet files in storage_path
            for root, dirs, files in os.walk(self.storage_path):
                for file in files:
                    if file.endswith('.parquet'):
                        file_path = os.path.join(root, file)
                        try:
                            file_size = os.path.getsize(file_path)
                            total_size += file_size
                            parquet_files.append((file_path, os.path.getmtime(file_path)))
                        except OSError as e:
                            logger.error("Error accessing file %s: %s", file_path, e)

            logger.info("Total parquet storage size: %.2f GB", total_size / (1024 ** 3))

            # If total size exceeds the maximum allowed, delete oldest files
            if total_size > self.max_storage_bytes:
                # Sort files by modification time (oldest first)
                parquet_files.sort(key=lambda x: x[1])
                for file_path, mod_time in parquet_files:
                    try:
                        file_size = os.path.getsize(file_path)
                        os.remove(file_path)
                        total_size -= file_size
                        logger.info("Deleted old parquet file: %s to manage storage.", file_path)
                        if total_size <= self.max_storage_bytes:
                            break
                    except OSError as e:
                        logger.error("Error deleting file %s: %s", file_path, e)

                logger.info("Storage management completed. Current size: %.2f GB", total_size / (1024 ** 3))
        except Exception as e:
            logger.error("Error during manage_storage: %s", e, exc_info=True)


def schedule_saving(listener, save_time):
    """Schedule daily data saving at the specified time."""
    def job():
        listener.save_data()

    schedule.every().day.at(save_time).do(job)
    logger.info("Scheduled daily save at %s.", save_time)

    while True:
        schedule.run_pending()
        time.sleep(1)


def main():
    listener = BybitListener(
        symbols=symbols_config['symbols'],
        storage_path=config['parquet_storage_path'],
        timezone=config['timezone'],
        max_storage_gb=3  # Set maximum storage to 3 GB
    )

    # Start WebSocket listener in a separate thread
    ws_thread = threading.Thread(target=listener.start_ws)
    ws_thread.daemon = True
    ws_thread.start()
    logger.info("WebSocket listener started.")

    # Schedule data saving in a separate thread
    scheduler_thread = threading.Thread(target=schedule_saving, args=(listener, config['save_time']))
    scheduler_thread.daemon = True
    scheduler_thread.start()
    logger.info("Scheduler thread started.")

    # Keep the main thread alive
    try:
        while True:
            time.sleep(10)
    except KeyboardInterrupt:
        logger.info("Shutting down BybitListener.")


if __name__ == "__main__":
    main()




# === config.yaml ===
# bybit_listener/config.yaml

testnet: false  # Set to true if using Bybit's testnet
channel_type: "linear"  # Options: "linear", "inverse", "spot"

# Path for storing data
parquet_storage_path: "./parquet_data/"

# Timezone for daily rollover (e.g., UTC, your local timezone)
timezone: "UTC"

# Scheduling time for saving data (HH:MM in 24-hour format)
save_time: "00:00"

# Log file path
log_file: "./logs/listener.log"

# Path to trigger file for on-demand saving (if applicable)
trigger_file_path: "./save_now.trigger"


# === requirements.txt ===
# bybit_listener/requirements.txt

websocket-client==1.6.1
pandas==2.1.1
schedule==1.2.0
pyyaml==6.0
pyarrow==13.0.0
pytz==2023.3


# === restart_listener.sh ===
#!/bin/bash

# Variables
SCRIPT="bybit-listener.py"
VENV_DIR="$(pwd)/env"         # Absolute path to the virtual environment
PROJECT_DIR="$(pwd)"          # Absolute path to the project directory
LOG_FILE="./logs/listener.log"

# Function to print messages with timestamp
echo_msg() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
}

echo_msg "Restarting Bybit Listener..."

# Activate virtual environment
source "$VENV_DIR/bin/activate"

# Navigate to the project directory
cd "$PROJECT_DIR"

# Stop the listener if it's running
if pgrep -f "$SCRIPT" > /dev/null
then
    pkill -f "$SCRIPT"
    echo_msg "Bybit Listener stopped."
    sleep 2
else
    echo_msg "Bybit Listener is not running."
fi

# Start the listener
nohup python "$SCRIPT" >> "$LOG_FILE" 2>&1 &
echo_msg "Bybit Listener restarted."


# === setup.sh ===
#!/bin/bash

# Exit immediately if a command exits with a non-zero status
set -e

# Variables (modify these as per your environment)
VENV_DIR="env"
STORAGE_PATH="./parquet_data"
LOG_DIR="./logs"
LOG_FILE="$LOG_DIR/listener.log"

# Function to print messages with timestamp
echo_msg() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
}

echo_msg "Starting setup..."

# Create necessary directories with restrictive permissions
echo_msg "Creating directories..."
mkdir -p "$STORAGE_PATH" && chmod 700 "$STORAGE_PATH"
mkdir -p "$LOG_DIR" && chmod 700 "$LOG_DIR"

# Navigate to the project directory
cd "$(dirname "$0")"

# Create virtual environment if it doesn't exist
if [ ! -d "$VENV_DIR" ]; then
    echo_msg "Creating Python virtual environment..."
    python3 -m venv "$VENV_DIR"
    echo_msg "Virtual environment created."
else
    echo_msg "Virtual environment already exists."
fi

# Activate virtual environment
echo_msg "Activating virtual environment..."
source "$VENV_DIR/bin/activate"

# Upgrade pip
echo_msg "Upgrading pip..."
pip install --upgrade pip

# Install dependencies
echo_msg "Installing dependencies..."
pip install -r requirements.txt

# Make start and restart scripts executable
chmod 700 start_listener.sh
chmod 700 restart_listener.sh

echo_msg "Setup completed successfully."


# === start_listener.sh ===
#!/bin/bash

# Variables
SCRIPT="bybit-listener.py"
LOG_FILE="$(pwd)/logs/listener.log"
VENV_DIR="$(pwd)/env"         # Absolute path to the virtual environment
PROJECT_DIR="$(pwd)"          # Absolute path to the project directory

# Function to print messages with timestamp
echo_msg() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
}

echo_msg "Starting Bybit Listener..."

# Activate virtual environment
source "$VENV_DIR/bin/activate"

# Navigate to the project directory
cd "$PROJECT_DIR"

# Start the listener script using nohup if not already running
if pgrep -f "$SCRIPT" > /dev/null
then
    echo_msg "Bybit Listener is already running."
else
    nohup python "$SCRIPT" >> "$LOG_FILE" 2>&1 &
    echo_msg "Bybit Listener started."
fi


# === symbols.json ===
{
    "symbols": [
        {
            "name": "BTCUSDT",
            "categories": ["trade"]
        },
        {
            "name": "ETHUSDT",
            "categories": ["orderBook"]
        }
    ]
}


# === test.py ===
from pybit.unified_trading import WebSocket
from time import sleep

ws = WebSocket(
    testnet=True,
    channel_type="linear",
)

def handle_message(message):
    print(message)

ws.orderbook_stream(50, "BTCUSDT", handle_message)

while True:
    sleep(1)

